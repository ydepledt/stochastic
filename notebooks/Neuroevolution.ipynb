{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pY3PbQ35IG8"
      },
      "source": [
        "# Neuroevolution\n",
        "\n",
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-sa/4.0/80x15.png\" /></a>&nbsp;| Dennis G. Wilson | <a href=\"https://supaerodatascience.github.io/stochastic/\">https://supaerodatascience.github.io/stochastic/</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was optimized for Google colab."
      ],
      "metadata": {
        "id": "zGw73sD65R6f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmobG0tO5IG-"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y xvfb python-opengl swig > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swig > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "JYx37NEK6ap3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xvfbwrapper"
      ],
      "metadata": {
        "id": "Z67mMvdD9hvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cma pyvirtualdisplay gymnasium[box2d]"
      ],
      "metadata": {
        "id": "-EC0xKKM6JCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOz_Torf5IHA"
      },
      "source": [
        "Consider a task where sequential decisions must be made. A common model is to consider that an environment gives an observation for each decision, or action, taken. We can then make decisions by choosing a function which takes in an environment state and gives out an action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds7kHtJM5IHB"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/SupaeroDataScience/stochastic/master/notebooks/imgs/ne_basics.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FydYJtZI5IHC"
      },
      "source": [
        "Evolutionary strategies are intended for continuous optimization and can easily be applied to the optimization of neural network parameters, or *neuroevolution*. The goal of this is to optimize the parameters of a function which can interact in an environment. A neural network can represent any function, so we can use it as a representation of our decision making function. The parameters of the neural network become the individual we are optimizing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRzN_BC15IHC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.multiprocessing as mp\n",
        "import numpy as np\n",
        "import gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYVmCNB_5IHD"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.l1 = nn.Linear(input_shape, 32)\n",
        "        self.l2 = nn.Linear(32, 32)\n",
        "        self.lout = nn.Linear(32, n_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.l1(x.float()))\n",
        "        x = F.relu(self.l2(x))\n",
        "        return self.lout(x)\n",
        "\n",
        "    def get_params(self):\n",
        "        p = np.empty((0,))\n",
        "        for n in self.parameters():\n",
        "            p = np.append(p, n.flatten().cpu().detach().numpy())\n",
        "        return p\n",
        "\n",
        "    def set_params(self, x):\n",
        "        start = 0\n",
        "        for p in self.parameters():\n",
        "            e = start + np.prod(p.shape)\n",
        "            p.data = torch.FloatTensor(x[start:e]).reshape(p.shape)\n",
        "            start = e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO_bOlPh5IHD"
      },
      "source": [
        "We'll add some visualization functionality to have the environment render directly in the notebook. To run this notebook in Google colab, uncomment and run the following lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4am2dOQ55IHD"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.ion();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdV6Jn3H5IHE"
      },
      "source": [
        "Following the framework of evolutionary policy search, we will optimize a neural network representing a policy and maximize the total reward over a single episode using this policy. In the following function, we use the policy function to take actions and calculate a reward given by the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lJVVPqb5IHE"
      },
      "outputs": [],
      "source": [
        "def evaluate(ann, env, visul=True):\n",
        "    # set the environment\n",
        "    obs, info = env.reset(seed=0, options={})\n",
        "    # visualization\n",
        "    if visul:\n",
        "        img = plt.imshow(env.render())\n",
        "    # total reward, objective for maximizing\n",
        "    total_reward = 0\n",
        "    # run the sequence of decisions\n",
        "    done = False\n",
        "    while not done:\n",
        "        # Use the neural network to make a decision based on observations\n",
        "        net_output = ann(torch.tensor(obs))\n",
        "        # the action is the value clipped returned by the nn\n",
        "        action = net_output.data.cpu().numpy().argmax()\n",
        "        # take a step in the environment\n",
        "        obs, reward, done, _, _ = env.step(action)\n",
        "        # track the total reward\n",
        "        total_reward += reward\n",
        "        # visualization of the action\n",
        "        if visul:\n",
        "            img.set_data(env.render())\n",
        "            plt.axis('off')\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "    return total_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ_xO38z5IHF"
      },
      "source": [
        "We've configured this for discrete action spaces. We can see a random neural network on different environments like `CartPole-v0`, `MountainCar-v0`, and `LunarLander-v2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKxqC0E55IHF"
      },
      "outputs": [],
      "source": [
        "env = gymnasium.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
        "ann = NeuralNetwork(env.observation_space.shape[0], env.action_space.n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OJPcCNS5IHF"
      },
      "outputs": [],
      "source": [
        "evaluate(ann, env, visul=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEuX7RuD5IHF"
      },
      "source": [
        "In order to evolve the parameters of this neural network, we will modify the parameters of the network using `set_params` with the genes of the new individual. In the evolutionary literature, this is referred to as a *direct encoding* as the neural network parameters are directly encoded in the genome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg9e0zY55IHG"
      },
      "outputs": [],
      "source": [
        "def fitness(x, ann, env, visul=False):\n",
        "    ann.set_params(x)\n",
        "    return -evaluate(ann, env, visul=visul)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBAUwaAi5IHH"
      },
      "outputs": [],
      "source": [
        "p = ann.get_params()\n",
        "np.shape(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uZpC5JC5IHH"
      },
      "source": [
        "We can first observe a random individual $x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3qyVkDi5IHH"
      },
      "outputs": [],
      "source": [
        "x = np.random.rand(len(p))\n",
        "-fitness(x, ann, env, visul=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2JnKneU5IHH"
      },
      "source": [
        "# CMA-ES for Neuroevolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trhf9qeg5IHI"
      },
      "source": [
        "We will now use CMA-ES for the Lunar Lander problem using the pycma package (https://github.com/CMA-ES/pycma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtEGF2I55IHI"
      },
      "outputs": [],
      "source": [
        "import cma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfT_PvzA5IHI"
      },
      "outputs": [],
      "source": [
        "np.random.seed(123)\n",
        "env = gymnasium.make('LunarLander-v2')\n",
        "ann = NeuralNetwork(env.observation_space.shape[0], env.action_space.n)\n",
        "es = cma.CMAEvolutionStrategy(len(ann.get_params()) * [0], 0.1, {'seed': 123})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqoiHwmp5IHJ"
      },
      "outputs": [],
      "source": [
        "for i in range(20):\n",
        "    solutions = np.array(es.ask())\n",
        "    fits = [fitness(x, ann, env) for x in solutions]\n",
        "    es.tell(solutions, fits)\n",
        "    es.disp()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jew1O-no5IHJ"
      },
      "outputs": [],
      "source": [
        "x = es.result[0]\n",
        "env = gymnasium.make('LunarLander-v2', render_mode=\"rgb_array\")\n",
        "-fitness(x, ann, env, visul=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwrDJeYg5IHJ"
      },
      "source": [
        "The results on LunarLander clearly show the benefits of CMA-ES; we have found a reasonable policy in a small number of generations. Applying CMA-ES to larger neural networks remains an open challenge, however, due to the vast number of parameters in ANNs. Specifically, CMA-ES calculates the covariance of all parameters, which is $O(n^2)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHgmMo-B5IHJ"
      },
      "outputs": [],
      "source": [
        "np.shape(es.sm.C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvGwML0m5IHK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}